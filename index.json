[{"content":"风噪特性 知己知彼，百战不殆。清楚了解风噪的特性才能够对症下药。\n高度非平稳性：因为风冲击传感器的产生的信号是快速变化且不稳定的 能量集中于中低频：通过频谱特征可以观察到 不同麦克风信号的风噪高度不相关：因为传感器之间的湍流是完全不相关的 风噪和语音是不相关的 问题描述 假设第一个麦克风接收到的信号为 $y_1(n)$ ，那么其包含语音 $x(n)$ 和风噪信号 $w_1(n)$ ：\n$$ y_1(n) = x(n) + w_1(n) $$\n第二个麦克风接收到的信号为 $y_2(n)$ ，那么其包含语音 $x(n)$ 和风噪信号 $w_2(n)$ ：\n$$ y_2(n) = x(n) + w_1(n) $$\n其中默认对麦克风信号进行了对齐以保证 $x(n)$ 在麦克风信号里是一致的。\n然后将两路麦克风信号通过短时傅里叶变换得到：\n$$ Y_1(t,f) = X(t,f) + W_1(t,f)\\\\ Y_2(t,f) = X(t,f) + W_2(t,f) $$\n风噪抑制的目标就是从两路麦克风信号 $Y_1(t,f),Y_2(t,f)$ 中恢复出 $X(t,f)$ 。\n方法 整体方法如下图所示：\n分为两阶段对风噪进行消除：第一阶段通过差和比来判断是否存在风噪，如果存在风噪则采用双麦的空间相关性和相似性的公式进行初步风噪抑制，不存在则直接输出。如果第一阶段存在风噪，那么第二阶段会再次采用质心法判断是纯风噪信号还是带残留风噪的信号，如果是残留风噪信号则进行残留风噪估计并进行维纳滤波。如果是纯风噪信号则使用一个极小值对其进行修正。\n以下是细节介绍：\n第一阶段 通过两路麦克风信号可以得到差信号 $D(t,f)$ 和和信号 $S(t,f)$ 如下：\n$$ \\begin{align} D(t,f) \u0026amp;= Y_1(t,f) - Y_2(t,f) = W_1(t,f) - W_2(t,f)\\\\ S(t,f) \u0026amp;= Y_1(t,f) + Y_2(t,f) = 2X(t,f)+W_1(t,f)+W_2(t,f) \\end{align} $$\n计算对应的功率谱：\n$$ \\begin{align} \\Phi_{D}(t,f) \u0026amp;= E[|D(t,f)|^2] = \\Phi_{W_1}(t,f) + \\Phi_{W_2}(t,f)\\\\ \\Phi_{S}(t,f) \u0026amp;= E[|S(t,f)|^2] = 4\\Phi_X(t,f) + \\Phi_{W_1}(t,f) + \\Phi_{W_2}(t,f) \\end{align} $$\n对其进行平滑操作：\n$$ \\Phi_D(t,f) = \\alpha_d \\Phi_D(t-1,f) + (1-\\alpha_d)|D(t,f)|^2\\\\ \\Phi_S(t,f) = \\alpha_s \\Phi_S(t-1,f) + (1-\\alpha_s)|S(t,f)|^2 $$\n由此可以求得差和比 $PR(t,f)$：\n$$ PR(t,f) = \\frac{\\Phi_D(t,f)}{\\Phi_S(t,f)} = \\frac{\\Phi_{W_1}(t,f) + \\Phi_{W_2}(t,f)}{4\\Phi_X(t,f) + \\Phi_{W_1}(t,f) + \\Phi_{W_2}(t,f)} $$\n当风噪占主导时候差和比为1，当语音占主导的时候差和比为0：\n$$ \\begin{align} lim_{\\Phi_{D}\\rightarrow \\infty}PR(t,f) = 1\\\\ lim_{\\Phi_{S}\\rightarrow \\infty}PR(t,f) = 0\\\\ \\end{align} $$\n为了结合风噪特性，在计算差和比的时候只取中低频进行计算，并求取平均：\n$$ \\overline{PR}(t) = \\frac{1}{k_2-k_1+1}\\sum_{k=k_1}^{k_2}w(k)PR(t,k) $$\n那么就可以通过 设置差和比阈值 $PR_0$ 来判断当前帧为语音还是带风噪：\n$$ IsWind(t) = \\begin{cases} \\ 1, \u0026amp; \\overline{PR(t)}\\ge PR_0\\\\ \\ 0, \u0026amp; \\overline{PR(t)} \u0026lt; PR_0 \\end{cases} $$\n如果是风噪则通过下式进行抑制，该公式考虑了双麦的空间相关性和相似性：\n$$ X_{s1}(t,f) = Y_1(t,f) + \\frac{1+j\\lambda}{1+\\lambda^2}(Y_2(t,f)-Y_1(t,f)) $$\n其中 $\\lambda = \\frac{|Y_2(t,f)|}{Y_1(t,f)}$ 。\n如果不是风噪则直接输出，不做处理。\n第二阶段 对于经过第一阶段风噪抑制的信号可能还会存在风噪残留，所以需要进行进一步的处理。\n因此在第二阶段会采用质心法求解第一阶段得到的信号的质心，进行风噪的检测 ：\n$$ SSC(t) = \\frac{sr}{N}\\frac{\\sum_{k=1}^{k_3}k\\Phi_{s1}(t,f)}{\\sum_{k=1}^{k_3}\\Phi_{s1}(t,f)} $$\n其中 $sr$ 为信号采样率， $N$ 为信号的进行傅里叶变换的点数，$\\Phi_{s1}(t,f)$ 是第一阶段输出的信号的平滑功率谱，通过下式计算：\n$$ \\Phi_{s1}(t,f) = \\alpha_{s1}\\Phi_{s1}(t-1,f) + (1-\\alpha_{s1}) |X_{s1}(t,f)|^2 $$\n那么就可以通过设置质心的阈值 $SSC_0$ 来判断当前帧是纯风噪还是带风噪信号 ：\n$$ IsNoisySpeech(t) = \\begin{cases} \\ 1, \u0026amp; \\overline{SSC(t)}\\ge SSC_0\\\\ \\ 0, \u0026amp; \\overline{SSC(t)} \u0026lt; SSC_0 \\end{cases} $$\n如果是纯风噪则直接进行最小值修正 ：\n$$ X_{s2}(t,f) = \\gamma X_{s1}(t,f) $$\n如果是带噪语音则进行维纳滤波 ，首先通过下式求解残留风噪的功率：\n$$ \\Phi_{W}(t,f) = PR(t,f) X_{s1}(t,f) $$\n然后求得先验信噪比：\n$$ \\xi(t,f) = \\alpha_{\\xi}\\xi(t-1,f) + (1-\\alpha_{\\xi})MAX[\\frac{X_{s1}(t,f)-\\Phi_W(t,f)}{\\Phi_W(t,f)},0] $$\n从而求得频率域维纳滤波的滤波器为：\n$$ H(t,f) = \\frac{\\xi(t,f)}{\\xi(t,f)+1} $$\n得到二阶段输出为：\n$$ X_{s2}(t,f) =H(t,f)X_{s1}(t,f) $$\n参数选择 超参数一共有如下：\n$\\alpha_d$ ：差信号功率谱的平滑系数，选择0.7 $\\alpha_s$ ：和信号功率谱的平滑系数，选择0.7 $\\alpha_{s1}$ ：第一阶段输出信号功率谱的平滑系数，选择0.8 $\\alpha_{\\xi}$ ：先验信噪比的平滑系数，选择0.5 $PR_0$ ：差和比阈值，取值0.15 $SSC_0$ ：质心阈值，取值175 $k_1$ ：差和比求和下限，取值1，关注0Hz以上的信号差和比 $k_2$ ：差和比求和上限，取值91，关注3000Hz以下的信号差和比 （3000·/8000*241+1） $k_3$ ：质心法求和上限，取值31，关注1000Hz以下的质心（1000/8000*241+1） $\\gamma$ ：用于修正的最小值，取值0.001，用于完全抑制纯风噪信号 $N$ ：傅里叶点数， 取值480 $sr$ ：采样率，取值16000 下面针对差和比阈值和质心的阈值进行介绍。\n差和比阈值 以下是干净语音，纯风噪，带噪语音的差和比对比。可以看到风噪的差和比基本都大于0.2，而带风噪则基本大于0.15，而语音的差和比则非常小。因此选取0.15作为阈值判断。\n此外一个显然的特性是，随着风速的增强（风噪的增强），带风噪的信号差和比逐渐趋近于1，符合前述分析。\n如果选取阈值小于0.15，会使得将更多语音认为是带噪语音，如果将阈值设置更大，则会漏检一部分的风噪。所以在设置的时候要特别关注。\n质心阈值 在 2-3m/s 风速下，风噪的质心会比带噪语音质心小。随着风速的增加，风噪质心增大，当风速大于 3.5m/s 时，风噪质心基本与带噪语音信号相当。故可以通过质心判别信号是风噪还是带噪语音信号。着重优化高风速下的算法性能。这里选取175，则是参考高风速下的质心分布。\n如果提升SSC阈值，会使得纯风噪无法被检测，如果降低这个阈值将会有更多风噪信号被认为带噪信号。\n效果 可以看到一阶段针对风速较低的风噪去除较好，但仍旧有残留，且高风噪段消除效果不明显。经过第二阶段之后则将风噪很好地进行了去除。\n从下表也可以看出，提出的方法在风速越高的情况下效果远优于其他算法。缺点也很明显，在低风速情况下效果还有待提升。\n啸叫\n","permalink":"https://yezhangyinge.github.io/posts/20240310_wind_noise/","summary":"户外场景下的语音通话质量受风噪的影响巨大，并且风噪具有短时波动剧烈的特性，对其进行有效抑制一直是相关风噪抑制技术的难点。本文提出一种两步骤的风噪抑制算法，充分利用不同通道风噪信号之间的不相关性和频谱分布特性来抑制风噪。第一步利用双通道信号间的差和功率比（差和比）来判断风噪是否存在，并利用双麦的空间相关性和相似性进行风噪初步抑制；第二步利用频谱质心法（质心法）和差和比估计残余风噪，再通过维纳滤波进行二级降噪。实验结果表明，在不同风速下本文提出的算法相比基线算法具有更强的风噪抑制能力，并且风噪越强效果提升越明显。","title":"NCMMSC 2023 基于差和比和质心修正的风噪抑制算法"},{"content":"简要介绍 本论文已经被 ICASSP 2024 接收，主要解决的问题是声学回声消除中存在延时和非线性失真情况下消除效果不好的问题。解决的方式为：\n采用 dual-path alignment (DPA) 实现网络的隐式对齐，改善存在延时情况下的声学回声消除性能。 采用两阶段网络来实现更好去除非线性情况下的回声。第一阶段估计幅度谱掩膜，第二阶段估计相位谱来实现回声消除。 问题描述 如下图，近端麦克风信号 $y(n)$ 包含回声信号 $e(n)$ 和 语音信号 $s(n)$ :\n$$ y(n) = s(n) + e(n) $$\n其中声学回声信号由远端参考信号 $x(n)$ 经过扬声器的非线性失真函数 $g(\\cdot)$ 并和回声路径进行卷积得到 $h(n)$ .\n$$ e(n) = h(n)*g(x(n)) $$\n本文会在频域进行回声消除任务，所以会有如下表达式：\n$$ Y(t,f) = S(t,f)+ E(t,f) $$\n其中 $t,f$ 分别代表帧索引和频点索引，整个回声消除的目的就是从 $Y(t,f)$ 中去除 $E(t,f)$ 并保留 $S(t,f)$ 。\n网络结构 网络整体结构如上，包含两阶段。第一阶段会估计一个幅度谱掩膜用于增强近端麦克风信号（并且DPA用来软对齐信号），第二阶段会估计一个复数谱掩膜用于矫正相位。\n第一阶段 第一阶段网络由 CRN 构成：包含 encoder block，recurrent block 和 decoder block。 encoder 会接收四路信号的输入： $X_m(t,f),X_{cm}(t,f),Y_m(t,f), Y_{cm}(t,f)$ 分别代表远端参考信号的幅度和压缩幅度谱，近端麦克风信号的幅度和压缩幅度谱。四路输入首先各自经过两层卷积来提取特征。然后送入 DPA 模块得到对齐后的远端参考信号的特征，并拼接在一起经过额外两层卷积来进一步提取特征。encoder的输出会送到 recurrent block 进一步获取帧之间的信息，最后使用 decoder 来估计幅度谱的掩膜 $M(t,f)$ 。\n从而估计出来的幅度谱为：\n$$ \\hat S_m(t,f) = M(t,f)\\odot Y_m(t,f) $$\n第二阶段 第二阶段网络同样由 CRN 构成。encoder 的输入包含估计出来的近端信号的实部和虚部，其通过下式计算：\n$$ \\hat S_{r}(t,f) = \\hat S_m(t,f)cos(\\theta_y(t,f))\\\\ \\hat S_{i}(t,f) = \\hat S_m(t,f)sin(\\theta_y(t,f)) $$\n其中 $\\theta_y(t,f)$ 代表 $Y(t,f)$ 的相位谱。然后网络会估计出一个复数谱掩膜 $[C_r(t,f), C_i(t,f)]$ 。通过该复数谱我们可以估计出近端语音的相位：\n$$ \\hat \\theta_s(t,f) = arctan(\\frac{C_i(t,f)Y_i(t,f)}{C_r(t,f)Y_r(t,f)}) $$\n最后估计出来的干净语音由下式求得：\n$$ \\hat S(t,f) = \\hat S_m(t,f)e^{j\\hat \\theta_s(t,f)} $$\n损失函数 损失函数包含两部分：压缩幅度谱损失和压缩复数谱损失。\n$$ L_{s_1} = \\frac{1}{TF}\\sum_{t,f}|\\hat S_m^{\\alpha}(t,f) - S_m^{\\alpha}(t,f)|^2\\\\ L_{s_2} = \\frac{1}{TF}\\sum_{t,f}|\\hat S_m^{\\alpha}(t,f)e^{j\\hat \\theta_s(t,f)} - S_m^{\\alpha}(t,f)e^{j\\theta_s(t,f)}|^2 $$\n然后将这个两个损失函数进行加权得到：\n$$ L = \\gamma L_{s_1} + (1-\\gamma)L_{s_2} $$\n其中 $\\gamma$ 的取值通过验证集获得。并且参考自论文 EFFECT OF NOISE SUPPRESSION LOSSES ON SPEECH DISTORTION AND ASR PERFORMANCE，其给出的结论是 幅度谱权重高的时候更加关注语音损伤，复数谱权重高的时候更加关注降噪。\n结果 以上是实验结果的汇总。通过 table 1 可以看到提出的 TSDPANet 相比于两个 baseline 在运算量和参数量都较低的情况下能够更加有效提升双讲和单讲下的性能。通过 table 2 可以看出 TSDPANet 在不同延时和存在非线性与否的情况下都能取得良好性能。最后，通过 table 3 中的消融实验可以看出，两阶段网络性能好于一阶段，这是因为两阶段能够更好优化相位。但是在不采用对齐的时候，两阶段网络效果不如一阶段，这主要因为没有对齐影响了第一阶段的幅度谱掩膜估计从而影响了相位估计。此外，通过 SPA 和 DPA 的对比可以看出，采用 DPA 可以取得更好的性能，这可以归功于 DPA 更好的特征提取能力和对齐能力，从而提升了幅度谱的估计和相位的矫正。\n另外需要说明的是从 $AECMOS_d$ 的结果看来效果并不是很好，网络不可避免对语音造成了损伤。因为第一阶段的掩膜的损伤无法通过第二阶段来进行补偿。后续考虑对这一部分进行改进，考虑使用DCT变换来将两阶段统一为一阶段。\n音频对比 以下是传统算法在高延时 (506ms)，存在非线性失真，双讲情况的效果对比：\n从上图可以看到，效果非常差，这是因为在有延时情况下传统算法将无法正确估计回声路径，这导致了无法正确抑制回声。此外双讲和非线性也严重影响了各类算法的收敛，导致效果不好。\n以下是论文中 baseline 与提出的网络的对比：\n可以看到其他 baseline 的效果并不好，一方面是因为没有进行对齐，另一方面在于提出的两阶段网络能够更好地处理复杂情况下的回声。\n但从 TSDPANet 和近端干净信号的对比可以看出，TSDPANet还是存在一定的语音损伤的。\nMore about alignment 如何通过网络实现软对齐的：核心在于将原来的帧内自相关，改为了求取帧间自相关。\n首先由于需要进行延时的是远端参考信号，所以会在远端参考信号 $X$ 前面进行padding，而近端麦克风信号 $Y$ 则不做处理。\n如果延时最长是 $n$ 帧 ，那么按照以下方式进行 $padding$ ：\n$$ [padding,\\cdots, padding, X(1,f),X(2,f),\\cdots,X(k,f)]^T $$\n同时 $unfold$ ：\n$$ \\begin{align} Delay=0\u0026amp;:X_{D_0} = [X(1,f),X(2,f),\u0026hellip;,X(k-1,f),X(k,f)]^T\\\\ Delay=1\u0026amp;:X_{D_1} = [padding,X(1,f),\u0026hellip;,X(k-2,f),X(k-1,f)]^T\\\\ Delay=2\u0026amp;:X_{D_2} = [padding,padding,\u0026hellip;,X(k-3,f),X(k-2,f)]^T\\\\ \u0026hellip;\\\\ Delay=n\u0026amp;:X_{D_n} = [padding,padding,\u0026hellip;,X(k-(n-1),f),X(k-n,f)]^T\\\\ \\end{align} $$\n所以有：\n$$ \\begin{align} Q \u0026amp;= [X_{D_n},X_{D_{n-1}},\u0026hellip;,X_{D_1},X_{D_0}]^T\\\\ K \u0026amp;= [Y(1,f),Y(2,f),\u0026hellip;,Y(k-1,f),Y(k,f)]\\\\ \\end{align} $$\n得到：\n$$ \\begin{align} D \u0026amp;= softmax{QK^T}\\\\ \u0026amp;= softmax{ \\begin{bmatrix} padding \u0026amp; padding \u0026amp; \\cdots \u0026amp; X(k-(n-1),f) \u0026amp; X(k-n,f) \\\\ \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ padding \u0026amp; padding \u0026amp; \\cdots \u0026amp; X(k-3,f) \u0026amp; X(k-2, f) \\\\ padding \u0026amp; X(1,f) \u0026amp; \\cdots \u0026amp; X(k-2,f) \u0026amp; X(k-1, f) \\\\ X(1,f) \u0026amp; X(2,f) \u0026amp; \\cdots \u0026amp; X(k-1,f) \u0026amp; X(k, f) \\\\ \\end{bmatrix} \\begin{bmatrix} Y(1,f) \\\\ Y(2,f) \\\\ \\vdots \\\\ Y(k-1,f) \\\\ Y(k,f) \\\\ \\end{bmatrix} } \\end{align} $$\n最后得到 D 为延时概率：\n$$ D = [prob_{D_n}, prob_{D_{n-1}},\\cdots,prob_{D_0}]^T $$\n通过这个概率对 Q ，也就是各个延时的特征进行加权则可以得到最后经过延时的特征：\n$$ \\hat X = sum[Q\\odot D] = QD^T = \\sum_{i = 0}^{n}prob_{D_i}X_{D_i} $$\n传统做法 To be done！\n","permalink":"https://yezhangyinge.github.io/posts/20240310_icassp/","summary":"Deep learning has become a popular approach for improving acoustic echo cancellation (AEC) in communication systems. However, existing systems mostly rely on traditional delay estimation methods, which often result in performance degradation due to inaccurate delay estimation. Furthermore, most deep learning-based methods use single-stage networks, the limited learning capability of which hinders the performance under harsh echo conditions. To address these challenges, this paper proposes a two-stage system with dual-path alignment. The two-stage strategy performs echo suppression on the magnitude spectrum in the first stage, followed by phase correction in the second one. In addition, the first stage processes two parallel features, the magnitude spectrum and its exponential compressed version, with which dual-path alignment is conducted to improve delay estimation. Experiment results demonstrate the effectiveness of the proposed system for echo suppression in challenging scenarios involving long delay, double-talk and nonlinear distortion.","title":"ICASSP2024 TWO-STAGE ACOUSTIC ECHO CANCELLATION NETWORK WITH DUAL-PATH ALIGNMENT"},{"content":"Linux Server Management Guide Reset Linux Easily, just download UltraIso and the needed version of Ubuntu\nUltraIso download link:UltraISO - The Ultimate ISO CD/DVD Image Utility\nUbuntu download link:Download Ubuntu Desktop | Download | Ubuntu\nThen, you should Burn ISO images to CD/DVD or USB drive\nLast, you just shut down the Linux server and reboot.\nWhen the Linux reboots, you should try to Enter F2/F12 to enter the BISO mode.\nchoose the USB to boot.\nFinally, you can start installing the Ubuntu system.\nInstall ssh sudo apt-get install openssh-server Reset cuda\u0026amp;cudnn Do it by yourself. I just found a link for you. You can follow it. But it may not work.\nUbuntu20.04下配置Nvidia显卡驱动+CUDA+CUDNN\nHow to save your time when you are a server administrator Add new user adduser user_name Become a sudoer You must be sudoer first. So that you can use the command below to become a sudoer.\nusermod -aG sudo user_name su vim /etc/sudoers # add the code below username ALL=(ALL:ALL) ALL Open/Shut graphic interface To make the GPU memory cleaner. (= =)\ninit 3 # shut graphic interface\rinit 5 # open graphic interface Mount disk I\u0026rsquo;m not quite sure about this command because I did it one and a half years ago. So I give you some references below.\nref: linux查看系统未被挂载的磁盘空间的方法\nref: Linux检查未挂载磁盘和为磁盘分区、挂载\nref: Linux的硬盘使用情况、挂载、SSD挂载\n# 1.see the mounted disk df -h Filesystem Size Used Avail Use% Mounted on tmpfs 6.3G 2.2M 6.3G 1% /run /dev/sda2 1.8T 38G 1.7T 3% / tmpfs 32G 0 32G 0% /dev/shm tmpfs 5.0M 0 5.0M 0% /run/lock /dev/sda1 511M 5.3M 506M 2% /boot/efi tmpfs 6.3G 80K 6.3G 1% /run/user/127 tmpfs 6.3G 68K 6.3G 1% /run/user/1001 tmpfs 6.3G 68K 6.3G 1% /run/user/1000 /dev/sdc1 1.8T 24K 1.7T 1% /mnt/sdc # 2.see all the disk include unmounted lsblk sda 8:0 0 1.8T 0 disk ├─sda1 8:1 0 512M 0 part /boot/efi └─sda2 8:2 0 1.8T 0 part / sdb 8:16 0 223.6G 0 disk # unmounted disk ├─sdb1 8:17 0 3.8G 0 part # unmounted part ├─sdb2 8:18 0 1K 0 part # unmounted part ├─sdb5 8:21 0 30.5G 0 part # unmounted part ├─sdb6 8:22 0 132.5G 0 part # unmounted part └─sdb7 8:23 0 56.8G 0 part # unmounted part sdc 8:32 0 1.8T 0 disk # unmounted disk └─sdc1 8:33 0 1.8T 0 part # unmounted part # 3.see extractly fdisk -l | grep \u0026#34;sd[bc]\u0026#34; Disk /dev/sdb: 223.57 GiB, 240057409536 bytes, 468862128 sectors /dev/sdb1 * 2048 7999487 7997440 3.8G 83 Linux /dev/sdb2 8001534 468860927 460859394 219.8G 5 Extended /dev/sdb5 8001536 71999487 63997952 30.5G 82 Linux swap / Solaris /dev/sdb6 72001536 349802495 277800960 132.5G 83 Linux /dev/sdb7 349804544 468860927 119056384 56.8G 83 Linux Partition 2 does not start on physical sector boundary. Disk /dev/sdc: 1.82 TiB, 2000398934016 bytes, 3907029168 sectors /dev/sdc1 2048 3907028991 3907026944 1.8T 83 Linux # 4.mount mkdir /mnt/sdc1 mount /dev/sdc1 /mnt/sdc1 # 5.automatically mount vim /etc/fstab # and add the content below /dev/sdc1 /mnt/sdc auto defaults,nofail,comment=cloudconfig 0 2 /dev/sdb6 /mnt/sdb6 auto defaults,nofail,comment=cloudconfig 0 2 /dev/sdb7 /mnt/sdb7 auto defaults,nofail,comment=cloudconfig 0 2 # 6.check if it works sudo mount -a # 7.umount a disk sudo umount /dev/sdb1 # 8.mkfs sudo mkfs.ext4 /dev/sdb mke2fs 1.46.5 (30-Dec-2021) Found a dos partition table in /dev/sdb Proceed anyway? (y,N) y Discarding device blocks: done Creating filesystem with 58607766 4k blocks and 14655488 inodes Filesystem UUID: 1e51f436-77d6-4dac-8807-937e9d566173 Superblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, 4096000, 7962624, 11239424, 20480000, 23887872 Allocating group tables: done Writing inode tables: done Creating journal (262144 blocks): done Writing superblocks and filesystem accounting information: done # 9.mount mount /dev/sdb /mnt/sdb # 10.automatically mount vim /etc/fstab /dev/sdb /mnt/sdb auto defaults,nofail,comment=cloudconfig 0 2 Check disk usage # 查看每个用户占用 sudo du -sh /home/* # 查看磁盘占用 df -hl # 查看用户进程 ps -aux # 查看单个文件夹下的文件占用 du -lh --max-depth=1 Some server-related trivia 3090ti*4 该服务器是最多人使用的（因为性能优于其他服务器），位置为1楼的机房，进入需要向机房管理人员申请然后才可以进入。\n该服务器\n1080ti*3 该服务器位置为609。\n在重启的时候需要手动进入BIOS，否则会无法进入界面导致乱码。\nTips：启动盘为三星的启动盘，其他启动盘可能是不对的。\n3080ti*4 该服务器位置为609。\n在重启之后需要手动按一下键盘才能够使用，所以在重启之后请耐心等待5-10mins，然后按一下键盘。\nTips：如果有空可以自己解决一下这个问题，让服务器重启之后自动进入系统。\n3080ti*2 该服务器维修了3次，位置为609。\n并且为上海服务商，所以如果维修需要联系上海的维修人员。\ntitan*2 该服务器为本人自行重装的系统，位置为407，进入该实验室需要用户名和密码。\n2070*2 该服务器处于问题状态，无法联网使用。位置为609。\nLocation pictures 以下是 N609 的服务器的位置。\n以下是 3090 服务器的位置。\n1.位置位于信工楼N105，也就是进门的右拐角就有一个机房\r2.怎么进去：找N608一个戴眼镜的老师然后让他帮忙开门\r3.具体3090位置，如下图，首先进门，然后右手边第一排就是服务器的位置，然后找到网络机柜25，就是我们服务器的位置\r4.有时候连接不上可能是因为服务器进入了休眠状态，重新按一下开机键，不需要长按就可以退出休眠 Some useful commands to fix bugs Could not ssh, maybe network problem # 0. check the ping, ssh to ensure the network work properly ping server_ip_addr # if don\u0026#39;t work then try to fix the network ssh username@server_ip_addr # if don\u0026#39;t work then try to fix ssh and ufw # 1. check the firework sudo ufw status # 2. check the ssh sudo ufw allow ssh How to fix GPU fan ERR! 这个问题产生的原因实在太多了，建议就是先重启，不行的再尝试其他解决方案或者返修。\n# just one solution reboot You are required to change your password immediately (password aged), You must change your password now and login again! 这个问题出现的原因不明，解决方案如下（如果你不是管理服务器的人员，请咨询管理服务器的人进行操作）：\n# 0.需要登录自己的账号，并修改为强密码，以下是一个可以获取强密码的网页 # 记得多试几次，密码长度10-15 https://tool.ip138.com/random/ # 1.登录上之后改为root账号 su # 2.为用户的密码设置加上期限 chage -M 99999 username # 3.修改用户强密码为其他密码 passwd username # 4.改为登录自己的账号 su username Failed to initialize NVML: Driver/library version mismatch 版本不匹配问题，因为服务器自动更新导致，解决方案如下：\n# 检查服务器的内核版本 cat /proc/driver/nvidia/version NVRM version: NVIDIA UNIX x86_64 Kernel Module 535.129.03 Thu Oct 19 18:56:32 UTC 2023 GCC version: gcc version 9.4.0 (Ubuntu 9.4.0-1ubuntu1~20.04.3) # 上面可以看到是 535.129.03 = driver_version modinfo nvidia # 一般在version行会输出不一样的驱动，所以就会导致问题，就算一样 # 也问题不大，删掉就完事 # 删除之前的东西 sudo /usr/bin/nvidia-uninstall sudo apt-get --purge remove nvidia-* sudo apt-get purge nvidia* sudo apt-get purge libnvidia* # 看看输出 sudo dpkg --list | grep nvidia-* # 解决方法是去官网查找对应的驱动 https://www.nvidia.cn/geforce/drivers/results/213200/ # 下载之后传送到服务器，并赋予权限 sudo chmod a+x NVIDIA-Linux-x86_64-driver_version.run # 重装，一路回车 sudo ./NVIDIA-Linux-x86_64-driver_version.run # 然后应该就活过来了 Update disable # 将下面的配置全部设置为0 vim /etc/apt/apt.conf.d/10periodic # 将下面的配置也全部设置为0 vim /etc/apt/apt.conf.d/20auto-upgrades # 重启 Unable to determine the device handle for GPU 0000:4C:00.0: Unknown Error 这个问题导致的原因很难确定：\n# 查看显卡状态 nvidia-debugdump --list # 以下为显示内容 Found 2 NVIDIA devices Device ID: 0 Device name: NVIDIA TITAN Xp (*PrimaryCard) GPU internal ID: 0323917060372 Error: nvmlDeviceGetHandleByIndex(): Unknown Error FAILED to get details on GPU (0x1): Unknown Error 显然是 1 卡坏了，一个最简单的方式就是停用 Bus_Id 为 0000:4C:00.0 的显卡：\n# drain 为停用模式， -p 指定显卡的Bus_Id， -m 启动停用模式 sudo nvidia-smi drain -p 0000:4C:00.0 -m 1 但是这只是一个权宜之计，并不能修复问题。\n","permalink":"https://yezhangyinge.github.io/posts/20240212_server_management_guide/","summary":"一些关于服务器管理的方法，方便后续管理服务器的人能够快速解决问题。","title":"Linux 服务器管理指南"},{"content":"守则 当你使用服务器的时候，你 不 允许动别人的文件。\n当你需要存放大文件到服务器的时候，你 不 允许将文件存放于 /home/your_user_name 下。你 必须 将文件存放在 /data/your_user_name 下。否则，你的文件将被清除。 如果你在 /data 下没有对应的文件夹，你可以使用下面的指令创建一个：\nmkdir /data/your_user_name 你 不 允许使用 sudo 来运行安装程序，除非 你得到了允许。\n你 不 允许占用服务器的过长时间，除非 你事先通知了大家，或者有紧急的事务。否则，你的进程将会被暂停。\nRules When you are using the Linux server, you should NOT touch other people\u0026rsquo;s files.\nWhen you need to store an amount of data, you should NOT store it in /home/your_user_name. You MUST store it in /data/your_user_name. Or, your data will be deleted without notification. If you do not have a directory in /data, you can create it by yourself using the command below.\nmkdir /data/user_name You should NOT use sudo to install or run anything without permission.\nYou should NOT occupy a server for a long time. Or your process will be killed.\n","permalink":"https://yezhangyinge.github.io/posts/20240212_rules_about_server/","summary":"一些关于实验室服务器使用你应该遵循的守则（中英都有，如果你不喜欢看中文，you can choose to read ENG version. = =）。","title":"Linux 服务器使用守则"},{"content":" 说在前面：写这个教程是因为自己尝试了不少方式来安装 webrtc，windows，linux，wsl 都进行了尝试。（折磨的不行= =）终于在这个假期将 webrtc 成功安装在了自己的 PC 上，所以特此记录，希望对后续希望学习 webrtc 的人能够有所帮助。毕竟，对于新手而言最难的第一步就是安装和配置环境。\nWhat you need 在进行以下安装的操作之前先确保你有这几个东西：\n一台 PC 较为快速的网络 科学上网的途径 如果没有上述条件，不建议进行以下的步骤。\nPrepare WSL 既然需要将 webrtc 安装在 wsl 上，那么第一步就是准备好 wsl。这一部分其实本人已经写了完整的教程了，这里将过程简单记录如下。（此外需要说明的是，安装 wsl 也可以直接通过 Microsoft Store 来安装，但是本人不喜欢将大文件安装在 C 盘，所以以下 wsl 的安装方是可以在任意磁盘下进行的。）\nDownload wsl 20.04版本：https://aka.ms/wslubuntu2004 18.04版本：https://aka.ms/wsl-ubuntu-1804 其他版本自行前往官网查找。\nChange file to .zip 下载后得到AppxBundle文件，将后缀名改为zip，然后解压。\n解压后得到如下内容：\n选择x64或ARM64的安装包均可均可，将后缀名改为zip，然后解压。\nInstall 此时需要先将解压后的文件放到一个文件夹（任意你开心的文件夹就行），命名为对应的ubuntu+版本， 然后将这个文件夹放到需要安装的目录下 点击ubuntu.exe进行安装 输入用户名 输入密码 确认密码 安装成功 More config 基本上，本人使用的是 powershell 来进行 windows 的操作，所以推荐将 wsl 的快捷打开加入到 powershell。\n按照下图操作\n打开 powershell 首先点击 1 位置，然后选择 settings 之后点击 2 位置，新增 profile 最后点击 3 位置，创建空的 profile 按照上述操作之后会看到以下界面，可以修改 Name 项将其命名为 ubuntu-xxx，然后将 command line 位置的路径改为安装好的 wsl 的 ubuntu.exe 的路径。\n之后就可以在 第一张图的 1 位置快速选择并打开自己的 wsl 了。\nInstall webrtc 本人使用的是 ubuntu2204，所以推荐你使用2204版本。当然版本不是一个大问题，不要安装太老的版本就行。\n准备好了 wsl 之后，就可以开始着手安装 webrtc 了（期待的搓手手~）。\n⚠⚠⚠以下操作均在 /home/your_name/ 路径下进行操作，在编辑 proxy 和 环境变量的时候需要将对应的 ipv4_address, proxy_port, your_name 设置为你自己的而不是直接 copy and paste，否则是一定会出错的。\nOpen wsl 第一步打开你辛辛苦苦安装好的 wsl，然后在 bash 下进行操作。\nProxy 为了能够拉取所需要的文件，首先你需要做的是配置好代理 (设置之前需要确保打开了 allow_lan)。配置方式如下：\nexport http_proxy=http://ipv4_address:proxy_port export https_proxy=http://ipv4_address:proxy_port export all_proxy=socks5://ipv4_address:proxy_port Install depot_tools 因为 webrtc 是通过 depot_tools 进行管理的，所以首先需要安装 depot_tools 。\ngit clone https://chromium.googlesource.com/chromium/tools/depot_tools.git 之后需要将 depot_tools 的路径设置为全局变量：\nvim ~/.bashrc # .bashrc 添加如下一行 export PATH=\u0026#34;$PATH:/home/your_username/depot_tools\u0026#34; # 添加完毕后保存并退出，执行以下语句 source ~/.bashrc 禁用 cpid：\nexport DEPOT_TOOLS_UPDATE=0 为 depot_tools 下载设置代理：\nvim .boto # 在 .boto 文件中输入以下内容 [Boto] proxy = ipv4_address proxy_port = proxy_port # 添加完内容后,保存 .boto 文件并将其设置为环境变量 export NO_AUTH_BOTO_CONFIG=/home/your_username/.boto Get webrtc 按照以下操作：\n# 创建 webrtc 文件夹，并进入 mkdir webrtc cd webrtc # 获取 webrtc 代码 fetch --nohooks webrtc # 由于文件比较多，所以可能会中断，如果中断了就使用下面的语句重新进行 gclient sync 在进行这一步操作的时候一定要有耐心，当然如果你的网速很快，那你的耐心忽略不计 = = 。\nInstall dependencies 使用以下语句安装依赖\ncd /home/your_username/webrtc/src ./build/install-build-deps.sh Compile 首先使用 depot_tools 中的 gn 语句来生成 ninja 工程文件：\ngn gen out/Default 然后进行编译：\nninja -C out/Default 编译成功之后可以在 src/out/Default/obj 文件夹里面看到 libwebrtc.a 文件，就代表成功了。\nUpdate 如果需要更新代码采取以下的步骤（当然本人没有尝试过，不想冒这个风险 = = ）：\ngit checkout master git pull origin master gclient sync Reference 以下是一些参考的链接，同时也包含了踩坑的一些解决方式，如果踩坑了不妨看看下面的链接，看看有没有类似的解决方式：\nUbuntu 20.04编译WebRTC_ubuntu 编译webrtc-CSDN博客\nubuntu - fetch v8 : \u0026quot;-bash: fetch: command not found\u0026quot; - Super User\n","permalink":"https://yezhangyinge.github.io/posts/20240212_install_webrtc/","summary":"说在前面：写这个教程是因为自己尝试了不少方式来安装 webrtc，windows，linux，wsl 都进行了尝试。（折磨的不行= =）终于在这个假期将 webrtc 成功安装在了自己的 PC 上，所以特此记录，希望对后续希望学习 webrtc 的人能够有所帮助。毕竟，对于新手而言最难的第一步就是安装和配置环境。\nWhat you need 在进行以下安装的操作之前先确保你有这几个东西：\n一台 PC 较为快速的网络 科学上网的途径 如果没有上述条件，不建议进行以下的步骤。\nPrepare WSL 既然需要将 webrtc 安装在 wsl 上，那么第一步就是准备好 wsl。这一部分其实本人已经写了完整的教程了，这里将过程简单记录如下。（此外需要说明的是，安装 wsl 也可以直接通过 Microsoft Store 来安装，但是本人不喜欢将大文件安装在 C 盘，所以以下 wsl 的安装方是可以在任意磁盘下进行的。）\nDownload wsl 20.04版本：https://aka.ms/wslubuntu2004 18.04版本：https://aka.ms/wsl-ubuntu-1804 其他版本自行前往官网查找。\nChange file to .zip 下载后得到AppxBundle文件，将后缀名改为zip，然后解压。\n解压后得到如下内容：\n选择x64或ARM64的安装包均可均可，将后缀名改为zip，然后解压。\nInstall 此时需要先将解压后的文件放到一个文件夹（任意你开心的文件夹就行），命名为对应的ubuntu+版本， 然后将这个文件夹放到需要安装的目录下 点击ubuntu.exe进行安装 输入用户名 输入密码 确认密码 安装成功 More config 基本上，本人使用的是 powershell 来进行 windows 的操作，所以推荐将 wsl 的快捷打开加入到 powershell。\n按照下图操作\n打开 powershell 首先点击 1 位置，然后选择 settings 之后点击 2 位置，新增 profile 最后点击 3 位置，创建空的 profile 按照上述操作之后会看到以下界面，可以修改 Name 项将其命名为 ubuntu-xxx，然后将 command line 位置的路径改为安装好的 wsl 的 ubuntu.","title":"How to install Webrtc on WSL"},{"content":"Enable MathJax 网络上有很多教程讲解了使用 Katex 来实现网页能够使用 latex 公式，但我是 typora 党，对于 Katex 并不熟悉。所以还是希望能够使用 MathJax 来实现在文章中支持 latex 数学公式。方法如下:\n找到 \\themes\\themes_name\\layouts\\partials\\footer.html 文件，在文件的最下方填上这段代码，使得能够支持MathJax\n\u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\u0026#34;\u0026gt; \u0026lt;/script\u0026gt; 但此时网页还并不支持 inline 的数学公式，所以需要在 footer.html 文件里面加上这段代码\n\u0026lt;script type=\u0026#34;text/x-mathjax-config\u0026#34;\u0026gt; MathJax.Hub.Config({ tex2jax: { inlineMath: [[\u0026#39;$\u0026#39;,\u0026#39;$\u0026#39;], [\u0026#39;\\\\(\u0026#39;,\u0026#39;\\\\)\u0026#39;]], displayMath: [[\u0026#39;$$\u0026#39;,\u0026#39;$$\u0026#39;], [\u0026#39;\\[\u0026#39;,\u0026#39;\\]\u0026#39;]], processEscapes: true, processEnvironments: true, skipTags: [\u0026#39;script\u0026#39;, \u0026#39;noscript\u0026#39;, \u0026#39;style\u0026#39;, \u0026#39;textarea\u0026#39;, \u0026#39;pre\u0026#39;], TeX: { equationNumbers: { autoNumber: \u0026#34;AMS\u0026#34; }, extensions: [\u0026#34;AMSmath.js\u0026#34;, \u0026#34;AMSsymbols.js\u0026#34;] } } }); \u0026lt;/script\u0026gt; 完成这些工作后，就可以愉快地在 post 的文章里面使用 latex 数学公式了。\nSome Rules 虽然可以开始大胆使用 latex 语法而且支持 inline 公式，但还是有一些点需要注意，避免 post 出去的文章中的公式出现意料之外的惊喜（笑）。\n在公式中不要使用 \\{ \\} ，改为使用方括号来实现。因为使用第一个并不能实现转义出花括号的效果。（烦） 在多行公式中需要使用 \\\\\\ 来代替 \\\\。 需要手动对公式进行编号，使用 \\tag{number} 不能使用 ^* 来表示共轭，需要改为 ^{\\star} 表示无穷的时候需要使用 \\infty 未来可能还会再添加。。。 ","permalink":"https://yezhangyinge.github.io/posts/20230929_mathjax_for_articles/","summary":"这篇文章简单介绍了如何使得hugo能够支持latex数学公式，除此以外还记录了一些与typora中latex不同的语法。","title":"Enable MathJax for Articles"},{"content":"首先声明，这篇文章包含不少公式。如果看的中途感到劳累了，请休息会，点杯coffee。当然，人生苦短，大可以放弃阅读传统算法，投入深度学习的怀抱吧。\nProblem Formulation 日常通话过程中，到达麦克风的信号除了语音信号 $x(t)$ ，往往还有噪声信号 $n(t)$ ，因此麦克风输出的信号 $y(t)$ 就包含了两个部分，语音和噪声（这里不考虑混响的情况，而且认为噪声是加性噪声）： $$ y(t) = x(t)+n(t) \\tag{1} $$ 噪声抑制要做的就是从麦克风信号中抑制噪声信号 $n(t)$ ，保留干净语音信号 $x(t)$。一般而言我们会使用 STFT 将信号搬移到时频域来进行噪声的抑制： $$ Y(t,f) = X(t,f)+N(t,f)\\tag{2} $$ 其中 $t$ 代表帧，$f$ 代表 frequency bin。\nPrior \u0026amp; Posterior SNR 传统噪声抑制最为关键的两个要素是：先验信噪比 $\\xi(t,f)$ 和后验信噪比 $\\gamma(t,f)$。计算方式如下： $$ \\xi(t,f) = \\frac{|X(t,f)|^2}{|N(t,f)|^2} \\tag{3} $$\n$$ \\gamma(t,f) = \\frac{|Y(t,f)|^2}{|N(t,f)|^2} \\tag{4} $$\n这两个信噪比可以将大部分传统的算法联系起来，形成一个统一的框架，所以在这里先为介绍。\n先验信噪比描述了干净语音功率和噪声功率之间的关系。后验信噪比则描述了带噪语音功率和噪声功率之间的关系。如果可以精确地估计这两个信噪比，就可以很好地对噪声进行抑制，所以传统算法基本围绕这两个信噪比的估计展开。\n值得注意的是，公式 $(3),(4)$ 都需要计算噪声的功率 $|N(t,f)|^2$，处理这个问题的方法是：噪声估计。\n另一个注意点，公式 $(3)$ 要求计算语音信号的功率 $|X(t,f)|^2$ （但一般不直接求取），处理这个问题的方法是：判决引导法 (DDA)。\nNoise Estimation 首先处理噪声估计的问题。传统算法下噪声估计有三种重要思想：\n噪声能量比较平稳，而且带语音的片段能量高于纯噪声的片段，所以可以通过跟踪功率最小值来获取噪声估计。 噪声功率估计想要稳定，通常要对功率谱进行平滑处理，也就是进行递归平均。 结合语音存在和不存在的概率，调节噪声估计在语音存在/不存在时各自的权重。 这三种思想各自都有对应的算法，在这里只介绍集合了三种思想的最小值控制的递归平均 (minima controlled recursive averaging, MCRA) 算法。\nMCRA 针对3，MCRA算法将噪声估计划分为了两类：\n$$ \\begin{align} speech\\ absent:\u0026amp; |N(t+1,f)|^2_{sa} = \\alpha |N(t,f)|^2 + (1-\\alpha)|Y(t,f)|^2 \\tag{5} \\\\ speech\\ present:\u0026amp; |N(t+1,f)|^2_{sp} = |N(t,f)|^2\\tag{6} \\end{align} $$\n第一个式子代表语音不存在的时候，此时需要对噪声进行重新的估计，同时针对2使用了递归平均来稳定噪声的估计。\n第二个式子代表语音存在的时候，因为此时语音存在，所以噪声延续上一帧的估计。\n针对3，设定一个语音存在概率 $p(t,f)$ 作为权重来将噪声估计的式子写为一个： $$ |N(t+1,f)|^2 = p(t,f)\\times |N(t+1,f)|^2_{sp} + (1-p(t,f))\\times |N(t,f)|^2_{sa} \\tag{7} $$ 此时需要对语音存在概率 $p(t,f)$ 进行估计， $$ p(t+1,f) = \\alpha_p p(t,f)+(1-\\alpha_p)\\delta [S_r(t,f)-\\Delta] \\tag{8} $$ 上式使用了针对2的递归平均来计算，以稳定对于语音存在概率的估计，其中 $\\delta[\\cdot]$ 代表指示函数。$S_r(t,f)$ 的计算公式如下： $$ S_r(t,f) = \\frac{\\sum_{i=-n}^{n}{w(i)|Y(t,f+i)|^2}}{min [\\sum_{i=-n}^{n}{w(i)|Y(t-1,f+i)|^2},\\sum_{i=-n}^{n}{w(i)|Y(t,f+i)|^2}]}\\tag{9} $$ 上式分号的上半部分 $\\sum_{i=-n}^{n}{w(i)|Y(t,k+i)|^2}$ 代表对邻近频率点进行功率的平均，下半部分 $min[\\cdot]$ 则代表不断获取局部的最小功率。整个式子的含义在于求得当前帧的功率与局部帧的最小功率的比值 $S_r(t,f)$ ，如果这个比值大于 $\\Delta$ ，那么就可以认为当前帧的能量是比较高的，需要用来更新对于语音存在概率的估计。这种想法来源于针对1的最小值功率的跟踪。\nSummary 整个MCRA算法是比较简单的，思路在于先通过 $(8),(9)$ 求取语音存在概率 $p(t,f)$ ，然后就可以根据 $(7)$ 来进行噪声的估计了。\nPrior SNR Estimation 通过对噪声功率的估计获取了 $|N(t,f)|^2$ ，同时带噪语音的功率 $|Y(t,f)|^2$ 也可以直接获取。因此根据 $(4)$ 可以得到后验信噪比 $\\gamma(t,f)$ 的估计。但先验信噪比应该如何估计呢？\n不妨大胆一点，我们假设噪声和语音是不相关的，可以得到： $$ \\begin{align} |Y(t,f)|^2 \u0026amp;= Y(t,f) \\times Y^*(t,f) \\tag{10}\\\\ \u0026amp;= [X(t,f)+N(t,f)] \\times [X(t,f)+N(t,f)]^{\\star} \\tag{11}\\\\ \u0026amp;= |X(t,f)|^2 +|N(t,f)|^2\\tag{12} \\end{align} $$ 这样，我们就可以得到干净语音的功率估计为： $$ |X(t,f)|^2 = |Y(t,f)|^2 - |N(t,f)|^2 \\tag{13} $$ 此时就可以通过 $(3)$ 来计算先验信噪比了。当然，我们还可以获得先验信噪比和后验信噪比的关系式： $$ \\xi(t,f) = \\frac{|Y(t,f)|^2-|N(t,f)|^2}{|N(t,f)|^2}= \\gamma(t,f)-1 \\tag{14} $$ 需要注意到，理论上分析有 $|Y(t,f)|^2 \\ge |N(t,f)|^2$ ，可是 $|N(t,f)|^2$ 是通过噪声估计得到的，存在大于 $|Y(t,f)|^2$ 的可能性，所以通过后验信噪比来估计先验信噪比还需要加入 $max[\\cdot]$ 函数来保证非负： $$ \\xi(t,f) =max[\\gamma(t,f)-1, 0] \\tag{15} $$\nDDA 但是，实际中一般会采取DDA来实现更加精确的估计： $$ \\xi(t,f) = \\alpha \\xi(t-1,f) + (1-\\alpha)max[\\gamma(t,f)-1,0] \\tag{16} $$ 注意到上式其实就是一个递归平均，第一项 $\\xi(t-1,f)$ 为前一帧估计的先验信噪比，第二项 $max[\\gamma(t,f)-1,0]$ 是当前帧估计的先验信噪比。\nSummary 对于先验信噪比的估计核心之一在于求得后验信噪比 $\\gamma(t,f)$ ，而后验信噪比本质上又和噪声估计息息相关。所以对于噪声的估计是传统里需要着重处理的问题。（但是，似乎在神经网络部分很少见到有人尝试对噪声进行估计了，可能因为估计难度比较高？）\nNoise Suppression 前面介绍了先验信噪比和后验信噪比的定义及其求法，但可能你还云里雾里不清楚为什么需要求这两个信噪比，而在这里我将通过几个经典的噪声抑制算法向你展示其美妙之处。\n1. Spectral Subtraction 顾名思义，谱减法就是从带噪语音功率谱减去噪声功率谱，得到干净语音的功率谱。那么会有下面的式子： $$ \\begin{align} |X(t,f)|^2 \u0026amp;= |Y(t,f)|^2-|N(t,f)|^2 \\tag{17} \\\\ \u0026amp;= [1-\\frac{1}{\\gamma(t,f)}]\\times |Y(t,f)|^2 \\tag{18} \\end{align} $$ 所以，只需要求得后验信噪比 $\\gamma(t,f)$ 就可以实现谱减法了。\n2. Wiener Filter 维纳滤波只做一件事：实现真实信号 $X(t,f)$ 与估计信号 $\\hat X(t,f)$ 的均方误差最小。而噪声抑制的方式是通过计算滤波器实现滤波： $$ \\hat X(t,f) = H(t,f)Y(t,f) \\tag{19} $$ 均方误差最小的优化式子为： $$ \\begin{align} min\\ J =\u0026amp; E {(X(t,f)-\\hat X(t,f))(X(t,f)-\\hat X(t,f))^* } \\tag{20}\\\\ =\u0026amp; |X(t,f)|^2+|H(t,f)|^2|Y(t,f)|^2 \\\\ \u0026amp;-X(t,f)H^{\\star}(t,f)Y^{\\star}(t,f) - X^{\\star}(t,f)H(t,f)Y(t,f) \\tag{21} \\end{align} $$ 然后求梯度，找到最小值： $$ \\nabla J_{H(t,f)} = 2H(t,f)|Y(t,f)|^2 - X(t,f)Y^{\\star}(t,f)-X^{\\star}(t,f)Y(t,f)=0 \\tag{22} $$ 上式可以得到： $$ \\begin{align} H(t,f) \u0026amp;= \\frac{X(t,f)Y^{\\star}(t,f)}{|Y(t,f)|^2} \\tag{23}\\\\ \u0026amp;= \\frac{X(t,f)(X^{\\star}(t,f)+N^{\\star}(t,f))}{|X(t,f)|^2+|N(t,f)|^2}\\tag{24}\\\\ \u0026amp;= \\frac{|X(t,f)|^2}{|X(t,f)|^2+|N(t,f)|^2}\\tag{25}\\\\ \u0026amp;= \\frac{\\xi(t,f)}{1+\\xi(t,f)}\\tag{26} \\end{align} $$ 注意上式 $(23)\\rightarrow(24)$ 使用了噪声和语音不相关的特性来得到分号下边，$(24)\\rightarrow(25)$ 同样使用了噪声和语音不相关特性来使得 $X(t,f)N^{\\star}(t,f)=0$ 。那么整个维纳滤波就可以转化为下式： $$ \\begin{align} X(t,f) \u0026amp;= H(t,f)Y(t,f)\\tag{27}\\\\ \u0026amp;= \\frac{\\xi(t,f)}{1+\\xi(t,f)}Y(t,f)\\tag{28} \\end{align} $$ 所以，只需要求得先验信噪比 $\\xi(t,f)$ 就可以实现维纳滤波了。（另一个有意思的点是，维纳滤波是复数谱上的估计，而不仅仅是幅度谱。）\n3. Statistic-Based Model 这一类方法一律依赖贝叶斯准则： $$ P(X|Y) = \\frac{P(Y|X)P(X)}{P(Y)}\\tag{29} $$ 上式中 $P(X|Y)$ 称为后验， $P(Y|X)$ 称为似然， $P(X)$ 称为先验，$P(Y)$ 称为证据。当最大化后验概率的时候称之为 MAP ，最大化似然的时候称之为 MLE。这一类估计需要复杂的数学推理，在这里就不进行了。\n但是，同样地其噪声抑制的表达式仍旧可以写为（以下以 MLE 为例子）： $$ |X(t,f)| = [ \\frac{1}{2}+\\frac{1}{2}\\sqrt{\\frac{\\xi_(t,f)}{1+\\xi(t,f)}} ]|Y(t,f)|\\tag{30} $$ 可以看到，仍旧可以通过计算 $\\xi(t,f)$ 先验信噪比来实现噪声抑制。\nOMLSA 基于统计学方法的最为出名的，可能还得是 OMLSA 算法了，其结合了两种思想：log-MMSE 最优估计器和语音存在概率。其增益函数的表达式如下： $$ \\begin{align} speech\\ absent:\u0026amp;G_{sa}(t,f) = G_{min}(t,f) \\tag{31}\\\\ speech\\ present:\u0026amp;G_{sp}(t,f) = \\frac{\\xi(t,f)}{1+\\xi(t,f)}\\int_{v(t,f)}^{\\infty}\\frac{1}{2}\\frac{e^{-t}}{t}dt \\tag{32} \\end{align} $$ 其中 $v(t,f) = \\frac{\\xi(t,f)\\gamma(t,f)}{1+\\xi(t,f)}$。\n与 MCRA 算法一致的，两者都需要估计语音存在概率 $p(t,f)$，通过语音存在概率可以将整个增益式子写为： $$ G(t,f) = G_{sp}(t,f)^{p(t,f)}\\times G_{sa}(t,f)^{1-p(t,f)} \\tag{33} $$ 与 MCRA 算法不一致的是，两者估计语音存在概率 $p(t,f)$ 的方式不一样，OMLSA 采取的估计方式为： $$ p(t,f) = [1+\\frac{q(t,f)}{1-q(t,f)}\\times(1+\\xi(t,f))\\times e^{-v(t,f)}]^{-1} \\tag{34} $$ 其中 $q(t,f)$ 为语音缺失概率，也就是将语音存在概率通过 $(34)$ 转化为了求解语音缺失概率。语音缺失概率计算公式为： $$ q(t,f) = 1-p_{local}(t,f)\\times p_{global}(t,f)\\times p_{frame}(t,f) \\tag{35} $$ 将求解转化为了三个语音存在概率 $p_{local}(t,f), p_{global}(t,f), p_{frame}(t,f)$ 进行计算。（真是绕的不行= =，具体这三个概率的计算见论文）\nsummary OMLSA 的增益函数的计算方式其实就两个关键：logMMSE 最优估计器和语音存在概率。\n在计算的时候需要首先通过计算语音缺失概率 $q(t,f)$ ，然后得到语音存在概率 $p(t,f)$ ，接着通过 $(31),(32),(33)$ 来计算增益式子。\n值得注意的是增益式子同样是由先验信噪比 $\\xi(t,f)$ 和后验信噪比 $\\gamma(t,f)$ 构成的。\nMCRA-OMLSA 由 cohen 提出的 MCRA-OMLSA 是一个非常经典的噪声抑制算法。其将语音存在概率分别用于噪声估计和增益函数的求解，使得能够在非稳态噪声的情况下也取得不错的性能。算法很简单，其实就是结合了OMLSA和MCRA，而在前面已经对两个算法进行介绍了，所以这里只给出一个流程框图：\n上图忽略了一些计算的细节（尤其是语音缺失和语音存在概率的计算细节），但是大致上是按照这个流程走的。\nTraditional VS Deep-Learning Traditional 就目前学习到的传统算法而言，都是基于下面的式子的： $$ |X(t,f)| = G(t,f)|Y(t,f)| \\tag{36} $$ 总体而言就是求解一个增益函数 $G(t,f)$ 来对幅度谱进行增强。\n这样做存在的问题：\n无法对相位进行增强（大部分） 对于噪声估计的要求十分苛刻，因为先验信噪比和后验信噪比的估计都离不开噪声估计 这样做带来的优点：\n不同于神经网络，这样做只需要很少，或者几乎没有参数的存储要求 不同于神经网络，这样做运算量小了非常多 Deep-Learning 传统方法与深度学习的噪声抑制存在非常强的关联性。深度学习的噪声抑制式子为（下式仅考虑了幅度）： $$ |X(t,f)|=M(t,f)|Y(t,f)| \\tag{37} $$ 显然可以看到，深度学习中的掩膜 $M(t,f)$ (Mask) 实际上就是传统方法中的增益 $G(t,f)$ (Gain) 函数。\n而深度学习优势在于：\n可以将相位也考虑进网络的优化，使得掩膜变为复数掩膜，带来相比于传统算法更好的性能 不再需要使用复杂的算法来估计噪声，先验，后验信噪比 可以通过让网络来自行学习如何估计掩膜（也就是增益，但带来的就是对于训练数据的要求） 能够处理更加复杂的噪声情况 同时深度学习的缺点在于：\n运算量较大 参数量较大 Summary 总体而言，传统的噪声抑制算法存在比较多的数学和工程知识，而且需要不少假设来简化理论推导。但是带来的是低复杂度，还有不错的效果。当然，由于对噪声估计的依赖，个人认为在使用神经网络去除部分噪声之后，将传统算法作为postfilter可能会是一个不错的选择。因为在通过神经网络消除部分噪声之后，可以尽可能保证带语音的片段能量高于纯噪声的片段，来满足噪声估计的要求。\n在神经网络大行其道的如今，传统算法并不是不能发挥其作用。工程中，综合考虑运算复杂度和性能时，结合轻量化的神经网络和传统算法可能会是一个较好的选择。\n","permalink":"https://yezhangyinge.github.io/posts/20230000_traditional_noise_suppression/","summary":"这篇文章主要是介绍一些传统的噪声抑制算法，比如谱减法，维纳滤波和MMSE。其中也包含了一些我个人对于传统算法的理解，还有一些对于传统与深度之间的联系的思考。","title":"Traditional Single-Channel NS"},{"content":"Create a markdown file hugo new posts/file_name.md 将写好的.md文件内容放置在file_name.md文件内。之后，需要添加文件的tags, categorise 和 summary\ntags：一般是琐碎的，精准的 categories：一般是抽象的，泛指的 summary：总结这篇文章的内容 最后将draft设置为false，即可。\nPreview the file 写好文章后第一步不应该commit，而是在本地查看是否符合预期。\nhugo server 用上面的指令会先生成本地预览文件，在 http://localhost:1313/ 显示。\nCommit 要提交article到网页，首先需要进入到 D:/hugo-papermod 的文件夹下 然后按照下面的指令操作即可。\nhugo cd public git add . git commit -m \u0026#34;update\u0026#34; git push origin master Change favicon 首先需要生成favicon文件，到这个网站可以获取: https://www.logosc.cn/logo/favicon 然后将favicon文件全部放置在 D:/hugo-papermod/static 文件夹下面。然后转到 D:/hugo-papermod/config.yml 文件夹里面，修改为对应生成的favicon的文件即可 Post iamge 在上传图片的时候会有额外的操作，你需要将图片放置在 /image 文件下，并将原本图片的路径改为这个路径。（后续考虑改进这个缺陷）\n","permalink":"https://yezhangyinge.github.io/posts/20230926_tutorial_post_a_article/","summary":"This is a tutorial of posting an article for myself.","title":"Post An Article"},{"content":" About Myself 叶藏吟歌这个名字是香菱学诗的一个对照。\n本意是自己做不到香菱学诗，所以只好寄希望于叶藏能吟唱出属于自己的歌谣🎵。\n自身是个理性的人，喜欢自然，阅读，跑步，滑板等一切能够让我沉浸其中的事情。\n从不刻意追求任何东西，只希望自己能够平稳，健康，快乐地度过这一生。同时善待身边的每一个人。\nAbout Research 现在在研究的东西为语音🗣，主要包含了noise suppression，acoustic echo cancellation 和 automatic speech recognition。 当然，主要是集中于单通道方向，多通道的涉猎不多，但对于MVDR和DOA等经典算法都有了解。欢迎相同研究方向的人与我进行讨论。\nAbout Hobby 喜欢的小说📖的类型为主要为推理小说，但不全是。其中会想要推荐给别人的作品有：\n小说推荐列表\r冈岛二人：《然后，门被关上了》，《克莱因壶》，《99%诱拐》 三津田信三：《如首无作祟之物》 三浦绫子：《冰点1》，《冰点2》 乙一：《在黑暗中等待》，《寂寞的频率》，《箱庭图书馆》，《平面狗》，《暗黑童话》，《ZOO》等 侯文咏：《危险心灵》，《白色巨塔》 绫辻行人：《钟表馆事件》 伊塔洛·卡尔维诺：《分成两半的子爵》，《不存在的骑士》，《树上的男爵》 严歌苓：《陆犯焉识》，《小姨多鹤》 阿加莎·克里斯蒂：《罗杰疑案》，《帷幕》 早坂吝：《虹の歯ブラシ 上木らいち発散》 高野和明：《消失的13级台阶》 贵志佑介：《来自新世界》，《黑屋吊影》 乔斯坦·贾德：《苏菲的世界》 威廉·彼得·布拉蒂：《驱魔人》 三毛：《亲爱的三毛》 余华：《许三观卖血记》，《活着》 岛田庄司：《占星术杀人魔法》 西泽保彦：《解体诸因》 殊能将之：《剪刀男》 藤原伊织：《离别的火焰》，《恐怖分子的洋伞》 喜欢的漫画很多很多，尤其推荐的画师为：\n漫画推荐列表\r石黑正数：《外天楼》，《女仆咖啡厅》 岩明均：《历史之眼》，《寄生兽》 古谷实：《17青春遁走》，《白晝之雨》，《庸才》 南胜久：《杀手寓言》 押見修造：《血之辙》，《恶之华》 楳圖一雄：《漂流教室》 松本大洋：《乒乓》 桂正和：《I\u0026rsquo;S》 井上雄彦：《浪客行》 三浦建太郎：《烙印战士》 喜欢的电影和电视剧也很多，但是就不做介绍了。\n喜欢的音乐类型也是非常繁杂，RNB，funk，pop等等。但最喜欢的歌手只有一个：陶喆。\n","permalink":"https://yezhangyinge.github.io/about/","summary":"About Myself 叶藏吟歌这个名字是香菱学诗的一个对照。\n本意是自己做不到香菱学诗，所以只好寄希望于叶藏能吟唱出属于自己的歌谣🎵。\n自身是个理性的人，喜欢自然，阅读，跑步，滑板等一切能够让我沉浸其中的事情。\n从不刻意追求任何东西，只希望自己能够平稳，健康，快乐地度过这一生。同时善待身边的每一个人。\nAbout Research 现在在研究的东西为语音🗣，主要包含了noise suppression，acoustic echo cancellation 和 automatic speech recognition。 当然，主要是集中于单通道方向，多通道的涉猎不多，但对于MVDR和DOA等经典算法都有了解。欢迎相同研究方向的人与我进行讨论。\nAbout Hobby 喜欢的小说📖的类型为主要为推理小说，但不全是。其中会想要推荐给别人的作品有：\n小说推荐列表\r冈岛二人：《然后，门被关上了》，《克莱因壶》，《99%诱拐》 三津田信三：《如首无作祟之物》 三浦绫子：《冰点1》，《冰点2》 乙一：《在黑暗中等待》，《寂寞的频率》，《箱庭图书馆》，《平面狗》，《暗黑童话》，《ZOO》等 侯文咏：《危险心灵》，《白色巨塔》 绫辻行人：《钟表馆事件》 伊塔洛·卡尔维诺：《分成两半的子爵》，《不存在的骑士》，《树上的男爵》 严歌苓：《陆犯焉识》，《小姨多鹤》 阿加莎·克里斯蒂：《罗杰疑案》，《帷幕》 早坂吝：《虹の歯ブラシ 上木らいち発散》 高野和明：《消失的13级台阶》 贵志佑介：《来自新世界》，《黑屋吊影》 乔斯坦·贾德：《苏菲的世界》 威廉·彼得·布拉蒂：《驱魔人》 三毛：《亲爱的三毛》 余华：《许三观卖血记》，《活着》 岛田庄司：《占星术杀人魔法》 西泽保彦：《解体诸因》 殊能将之：《剪刀男》 藤原伊织：《离别的火焰》，《恐怖分子的洋伞》 喜欢的漫画很多很多，尤其推荐的画师为：\n漫画推荐列表\r石黑正数：《外天楼》，《女仆咖啡厅》 岩明均：《历史之眼》，《寄生兽》 古谷实：《17青春遁走》，《白晝之雨》，《庸才》 南胜久：《杀手寓言》 押見修造：《血之辙》，《恶之华》 楳圖一雄：《漂流教室》 松本大洋：《乒乓》 桂正和：《I\u0026rsquo;S》 井上雄彦：《浪客行》 三浦建太郎：《烙印战士》 喜欢的电影和电视剧也很多，但是就不做介绍了。\n喜欢的音乐类型也是非常繁杂，RNB，funk，pop等等。但最喜欢的歌手只有一个：陶喆。","title":"About"}]